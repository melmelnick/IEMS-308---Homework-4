{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import math\n",
    "import sklearn.feature_extraction.text as nlp\n",
    "import sklearn.metrics.pairwise as metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by creating the corpus\n",
    "bi2013 = []\n",
    "folder = '../BI-articles/2013/'\n",
    "\n",
    "for article in os.listdir(folder):\n",
    "    with open(folder + '//' + article, 'r', encoding = 'latin-1') as art13:\n",
    "        lines = art13.read()\n",
    "        bi2013.append(lines)\n",
    "    art13.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi2014 = []\n",
    "folder = '../BI-articles/2014/'\n",
    "\n",
    "for article in os.listdir(folder):\n",
    "    with open(folder + '//' + article, 'r', encoding = 'latin-1') as art14:\n",
    "        lines = art14.read()\n",
    "        bi2014.append(lines)\n",
    "    art14.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_all = bi2013 + bi2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for article in bi_all:\n",
    "    tokens = word_tokenize(article)\n",
    "    for token in tokens:\n",
    "        all_tokens.append(token)\n",
    "        \n",
    "unique_tokens = set(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "for article in bi_all:\n",
    "    sent_token = sent_tokenize(article)\n",
    "    for sentence in sent_token:\n",
    "        sents.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sents = [word_tokenize(s) for s in sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code creates a bag of words list, filled with a dictionary that states how many occurences there are of each word in a given document. This machine did not have enough computing power to run this block of code, so any code from here will be commented out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744469"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag_of_words = []\n",
    "# for t_sent in t_sents:\n",
    "#     words_dict = dict.fromkeys(unique_tokens, 0)\n",
    "#     for word in t_sent:\n",
    "#         words_dict[word] += 1\n",
    "#     bag_of_words.append(words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the tf score for a given word and document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_tf(word_dict):\n",
    "#     tf_dict = {}\n",
    "#     n = words_dict[max(words_dict, key=words_dict.get)]\n",
    "#     for word, count in words_dict.items():\n",
    "#         tf_dict[word] = 0.5 + 0.5 * count / float(n)\n",
    "#     return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the tf_scores\n",
    "# all_tf = []\n",
    "# for u in bow:\n",
    "#     all_tf.append(compute_tf(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the idf score for a given word and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_idf(bi_all):\n",
    "#     N = len(documents)\n",
    "    \n",
    "#     idf_dict = dict.fromkeys(unique_tokens, 0)\n",
    "#     for article in bi_all:\n",
    "#         for word, val in article.items():\n",
    "#             if val > 0:\n",
    "#                 idf_dict[word] += 1\n",
    "    \n",
    "#     for word, val in idf_dict.items():\n",
    "#         idf_dict[word] = math.log(N / float(val))\n",
    "#     return idf_dict\n",
    "\n",
    "#\n",
    "# Calculating all of the idf scores\n",
    "# all_idf = compute_idf(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to computer the tfidf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_tfidf(one_tf, idfs):\n",
    "#     tfidf = {}\n",
    "#     for word, val in one_tf.items():\n",
    "#         tfidf[word] = val * idfs[word]\n",
    "#     return tfidf\n",
    "\n",
    "\n",
    "# Calculating the tfidf scores\n",
    "# all_tfidf = []\n",
    "# for d in all_tf:\n",
    "#     all_tfidf.append(compute_tfidf(d, all_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section of the code would be used to create the term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame(all_tfidf)\n",
    "\n",
    "# vectorizer = nlp.TfidfVectorizer()\n",
    "# vectors = vectorizer.fit_transform(sents)\n",
    "# feature_names = vectorizer.get_feature_names()\n",
    "# dense = vectors.todense()\n",
    "# denselist = dense.tolist()\n",
    "# df2 = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to pull out the keywords of a Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_convert = spacy.load('en_core_web_sm')\n",
    "# def get_keywords(question):\n",
    "#     question = nlp_convert(question)\n",
    "#     keywords = []\n",
    "#     for token in question:\n",
    "#         if token.pos_ != 'PUNCT' and token.is_stop == False:\n",
    "#             keywords.append(str(token))\n",
    "            \n",
    "#     return keywords\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to calculate the score of a given sentence in the document term matrix based on the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_sent_score(question,document):\n",
    "#     keywords = get_keywords(question)\n",
    "    \n",
    "#     num_keywords = 0\n",
    "#     for keyword in keywords:\n",
    "#         if keyword in document:\n",
    "#             num_keywords += 1\n",
    "    \n",
    "#     tfidf_match_sum = 0\n",
    "#     for keyword in keywords:\n",
    "#         if keyword in document:\n",
    "#             tfidf_match_sum += df2.iloc[document, keyword]\n",
    "    \n",
    "#     tfidf_non_match_sum = 0\n",
    "#     for keyword in keywords:\n",
    "#         if keyword in document:\n",
    "#             continue\n",
    "#         else:\n",
    "#             tfidf_match_sum += df2.iloc[document, keyword]\n",
    "            \n",
    "#     final_score = num_keywords + tfidf_match_sum - tfidf_non_match_sum\n",
    "#     return final_score\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function to find the highest score in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_highest_score(question):\n",
    "#     highest_score = -1000\n",
    "#     best_doc = None\n",
    "#     for document in bi_all:\n",
    "#         current_score = calc_sent_score(question, document)\n",
    "#         if current_score > highest_score:\n",
    "#             highest_score = current_score\n",
    "#             best_doc = bi_all.index(document)\n",
    "            \n",
    "#     return best_doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function classifies which question you are asking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #if a question is asked, we need to pick out the keywords to search for\n",
    "# def q_class(question):\n",
    "#     if 'bankrupt' in question:\n",
    "#         q_class = 1\n",
    "#     elif 'GDP' in question:\n",
    "#         q_class = 2\n",
    "#     elif 'percentage' in question:\n",
    "#         q_class = 3\n",
    "#     elif 'CEO' in question:\n",
    "#         q_class = 4\n",
    "#     else:\n",
    "#         return 'Not a valid question'\n",
    "    \n",
    "#     return q_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts the answer based on the class of question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_answer(question)\n",
    "#     qclass = q_class(question)\n",
    "#     best_doc = find_highest_score(question)\n",
    "    \n",
    "#     converted_doc = nlp_convert(bi_all[best_doc])\n",
    "    \n",
    "#     if qclass == 1:\n",
    "#         ents = []\n",
    "#         for ent in converted_doc.ents:\n",
    "#             if ent == 'ORG':\n",
    "#                 ents.append(ent)\n",
    "#         answer == ents\n",
    "        \n",
    "#     elif qclass == 2:\n",
    "#         nns = []\n",
    "#         for token in converted_doc:\n",
    "#             if token.pos_ == 'NN'\n",
    "#                 nns.append(token)\n",
    "#         answer == nns\n",
    "        \n",
    "#     elif qclass == 3:\n",
    "#         nums = []\n",
    "#         for token in converted_doc:\n",
    "#             if token.pos_ == 'NUM'\n",
    "#                 nums.append(token)\n",
    "#         answer == nums\n",
    "    \n",
    "#     elif qclass == 4:\n",
    "#         ceos = []\n",
    "#         for ent in converted_doc.ents:\n",
    "#             if ent.label_ == 'PERSON'\n",
    "#                 ceos.append(ent)\n",
    "#         answer == ceos\n",
    "        \n",
    "#     else:\n",
    "#         return('Invalid Question')\n",
    "    \n",
    "    \n",
    "#     return answer\n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
